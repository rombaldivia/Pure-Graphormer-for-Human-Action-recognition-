#%%writefile graphormer_spatial.py
#uncomment the top line for direct deployment in environments like Kaggle or Colab.
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Graphormer fine-tuning / training for NTU-RGB-D-120 skeletons (25 joints, 3D)


import os, random, argparse, pickle, time, json
from pathlib import Path
from pprint import pprint

import numpy as np, pandas as pd
import matplotlib.pyplot as plt, seaborn as sns
import torch, torch.nn as nn
from torch.utils.data import Dataset, DataLoader, Subset
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tqdm import tqdm


def set_seed(seed: int = 42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.benchmark = True


def remap_keys(sd: dict) -> dict:
    out = {}
    for k, v in sd.items():
        nk = (
            k.replace("input_proj", "proj")
              .replace("ln.", "norm.")
              .replace("cls_token", "cls")
        )
        if nk.startswith("encoder."):
            nk = "enc" + nk[len("encoder") :]
        out[nk] = v
    return out


class MMAction2KeypointDataset(Dataset):
    def __init__(self, data: dict, idx_list: list[int],
                 num_frames: int = 16, jitter: int = 2,
                 drop_tokens: float = 0.0, is_train: bool = True):
        self.samples   = [data["annotations"][i] for i in idx_list]
        self.num_frames, self.jitter, self.drop_tokens = num_frames, jitter, drop_tokens
        self.is_train  = is_train

        first = self.samples[0]["keypoint"]
        if first.ndim == 4:       # (1,T,25,3)
            first = first[0]
        self.joints, self.channels = first.shape[1:]  # (T,25,3) → 25,3

    def __len__(self):    return len(self.samples)

    def __getitem__(self, idx: int):
        item = self.samples[idx]
        kp   = item["keypoint"]
        kp   = kp[0] if kp.ndim == 4 else kp      # (T,25,3)
        label = item["label"]


        if self.is_train and self.jitter:
            shift = np.random.randint(-self.jitter, self.jitter + 1)
            kp = np.roll(kp, shift, axis=0)

        # -- crop/pad to num_frames -------------------------------------------
        T = kp.shape[0]
        if T > self.num_frames:
            s  = (T - self.num_frames) // 2
            kp = kp[s:s+self.num_frames]
        elif T < self.num_frames:
            pad = np.repeat(kp[-1][None], self.num_frames - T, axis=0)
            kp  = np.concatenate([kp, pad], axis=0)

        
        kp = (kp - kp.mean(axis=1, keepdims=True)) / (kp.std(axis=1, keepdims=True)+1e-5)

      
        if self.is_train and np.random.rand() < .5:
            kp[..., 0] *= -1     # flip eje-X

        
        if self.is_train and self.drop_tokens > 0:
            n_drop = int(round(self.num_frames * self.drop_tokens))
            if n_drop:
                idx_drop = np.random.choice(self.num_frames, n_drop, replace=False)
                kp[idx_drop] = 0

        return torch.from_numpy(kp).float(), label



class GraphormerForHAR(nn.Module):
    def __init__(self, num_joints: int, seq_len: int,
                 num_classes: int = 120, d_model: int = 256,
                 num_heads: int = 8, num_layers: int = 6,
                 dropout_p: float = .2, in_channels: int = 3):
        super().__init__()
        self.proj = nn.Linear(in_channels, d_model)
        self.temb = nn.Embedding(seq_len, d_model)
        self.jemb = nn.Embedding(num_joints, d_model)
        self.drop = nn.Dropout(dropout_p)
        self.norm = nn.LayerNorm(d_model)

        layer = nn.TransformerEncoderLayer(d_model, num_heads,
                                           dropout=dropout_p, batch_first=True)
        self.enc  = nn.TransformerEncoder(layer, num_layers)
        self.cls  = nn.Parameter(torch.randn(1, 1, d_model))
        self.head = nn.Linear(d_model, num_classes)

    def forward(self, x):        # x: (B,T,J,C)
        B, T, J, C = x.shape
        x = self.proj(x)                                          # (B,T,J,d)
        x = x + self.temb(torch.arange(T, device=x.device)).unsqueeze(1)
        x = x + self.jemb(torch.arange(J, device=x.device))
        x = self.norm(self.drop(x.reshape(B, T*J, -1)))

        x = torch.cat([self.cls.expand(B, -1, -1), x], dim=1)     # [CLS] token
        x = self.enc(x)
        cls = x[:, 0]
        avg = x[:, 1:].mean(dim=1)
        return self.head(cls + avg)


class FocalLoss(nn.Module):
    def __init__(self, gamma: float = 1.5, weight=None):
        super().__init__()
        self.g, self.ce = gamma, nn.CrossEntropyLoss(weight=weight)

    def forward(self, logits, targets):
        ce = self.ce(logits, targets)
        pt = torch.exp(-ce)
        return ((1-pt) ** self.g * ce).mean()


@torch.no_grad()
def validate(model, loader, crit, device):
    model.eval()
    loss = cor = tot = 0
    preds, gts  = [], []
    for x, y in loader:
        x, y = x.to(device), y.to(device)
        with torch.amp.autocast(device_type=device.type, dtype=torch.float16,
                                enabled=device.type == 'cuda'):
            out = model(x)
            l   = crit(out, y)
        loss += l.item()
        p      = out.argmax(1)
        cor   += (p == y).sum().item()
        tot   += y.size(0)
        preds.extend(p.cpu().tolist())
        gts.extend(y.cpu().tolist())
    return loss / len(loader), 100 * cor / tot, preds, gts


def main(a):
    set_seed()

    use_cuda = a.device == 'cuda' and torch.cuda.is_available()
    device   = torch.device('cuda' if use_cuda else 'cpu')
    print(f"▶ Device: {device}")

    
    data_path = Path(a.pkl)
    with open(data_path, 'rb') as f:
        data = pickle.load(f)

    
    bad_ids = set()
    if a.missing_txt:
        with open(a.missing_txt) as f:
            bad_ids = {ln.strip() for ln in f if ln.strip()}
        print(f" skipping {len(bad_ids)} corrupted clips ")

  
    split_dict = data.get('split', {})
    def ids_to_idx(split_key):
        if split_key not in split_dict:
            raise ValueError(f"split '{split_key}' no existe en el .pkl")
        wanted_ids = set(split_dict[split_key])
        return [i for i,s in enumerate(data['annotations'])
                if s['frame_dir'] in wanted_ids and s['frame_dir'] not in bad_ids]

    idx_tr = ids_to_idx(a.train_split)
    idx_va = ids_to_idx(a.val_split)

  
    idx_te = idx_va

    print(f"Train: {len(idx_tr)} clips  | Val: {len(idx_va)} clips")
    labels = [data['annotations'][i]['label'] for i in idx_tr]
    print(f" train labels: {len(set(labels))}")

  
    common = dict(batch_size=a.batch, num_workers=a.num_workers,
                  pin_memory=use_cuda)

    dl_tr = DataLoader(MMAction2KeypointDataset(
                           data, idx_tr, a.frames, a.jitter,
                           a.drop_tokens, True),
                       shuffle=True, **common)

    dl_va = DataLoader(MMAction2KeypointDataset(
                           data, idx_va, a.frames, a.jitter,
                           0.0, False),
                       shuffle=False, **common)

    dl_te = DataLoader(MMAction2KeypointDataset(
                           data, idx_te, a.frames, a.jitter,
                           0.0, False),
                       shuffle=False, **common)

    in_ch   = 3
    num_cls = 120
    model   = GraphormerForHAR(25, a.frames, num_cls,
                               a.d_model, a.heads, a.layers,
                               a.dropout, in_ch).to(device)

    if use_cuda and torch.cuda.device_count() > 1:
        print(f"🖥️  DataParallel: {torch.cuda.device_count()} GPUs")
        model = nn.DataParallel(model)

  
    if a.resume:
        print(" Resume", a.resume)
        raw  = torch.load(a.resume, map_location=device)
        sd   = remap_keys(raw.get('state_dict', raw))
        base = model.module.state_dict() if isinstance(model, nn.DataParallel)\
                                         else model.state_dict()
        filt = {k: v for k, v in sd.items()
                if k in base and v.shape == base[k].shape}
        (model.module if isinstance(model, nn.DataParallel) else model)\
            .load_state_dict(filt, strict=False)

    
    class_cnt = np.bincount(labels, minlength=num_cls)
    if (class_cnt == 0).any():
        print('⚠ Clase(s) faltantes en train → loss sin pesos')
        class_w = None
    else:
        class_w = torch.tensor(1.0 / (class_cnt + 1e-6),
                               dtype=torch.float32).to(device)

    if a.label_smooth > 0:
        crit = nn.CrossEntropyLoss(weight=class_w,
                                   label_smoothing=a.label_smooth)
    else:
        crit = FocalLoss(1.5, weight=class_w) if class_w is not None \
               else FocalLoss(1.5)

  
    def make_optim():
        opt = torch.optim.AdamW(
            filter(lambda p: p.requires_grad, model.parameters()),
            lr=a.lr, weight_decay=a.wd)
        if a.scheduler == 'onecycle':
            steps = a.epochs * len(dl_tr)
            sched = torch.optim.lr_scheduler.OneCycleLR(
                        opt, max_lr=a.lr, total_steps=steps,
                        pct_start=a.warmup_epochs / max(a.epochs, 1),
                        div_factor=25.0, final_div_factor=1e4)
        else:
            sched = torch.optim.lr_scheduler.CosineAnnealingLR(
                        opt, T_max=a.epochs)
        return opt, sched

    opt, sched = make_optim()
    scaler     = torch.amp.GradScaler(enabled=use_cuda)

    lr_file = Path('hyper_lr.txt'); lr_file.write_text(str(a.lr))
    last_lr  = lr_file.stat().st_mtime


    best = pat = 0
    logs = []
    Path('metrics').mkdir(exist_ok=True)

    for ep in range(1, a.epochs + 1):
        model.train(); tot = 0
        pbar = tqdm(dl_tr, desc=f"E{ep}/{a.epochs}", leave=False)

        # hot-reload LR
        if lr_file.exists() and lr_file.stat().st_mtime != last_lr:
            try:
                lr_new = float(lr_file.read_text().strip())
                for g in opt.param_groups: g['lr'] = lr_new
                print(f"⚡ LR → {lr_new:.3e}")
                last_lr = lr_file.stat().st_mtime
            except ValueError:
                print("❌ hyper_lr.txt inválido")

        for x, y in pbar:
            x, y = x.to(device), y.to(device)
            opt.zero_grad()
            with torch.amp.autocast(device_type=device.type,
                                    dtype=torch.float16,
                                    enabled=use_cuda):
                loss = crit(model(x), y)
            scaler.scale(loss).backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            scaler.step(opt); scaler.update(); sched.step()
            tot += loss.item(); pbar.set_postfix({'loss': f"{loss.item():.3f}"})

        tl = tot / len(dl_tr)
        vl, va, preds, gts = validate(model, dl_va, crit, device)
        print(f"E{ep:03}/{a.epochs} | Tr {tl:.3f} | Va {vl:.3f} | Acc {va:.2f}%")

        logs.append([ep, tl, vl, va])
        if va > best:
            best = va; pat = 0
            torch.save(model.module.state_dict() if isinstance(model, nn.DataParallel)
                       else model.state_dict(), a.save_best)
        else:
            pat += 1
            if pat >= a.stop:
                print("⏹ Early stop"); break

        pd.DataFrame(logs, columns=['epoch','train','val','acc']) \
          .to_csv('metrics/curve.csv', index=False)

        cm = confusion_matrix(gts, preds, normalize='true')
        plt.figure(figsize=(10,8))
        sns.heatmap(cm, cmap='YlGnBu', vmin=0, vmax=1, square=True)
        plt.xlabel('Pred'); plt.ylabel('GT'); plt.tight_layout()
        plt.savefig('metrics/confmat.png', dpi=250); plt.close()

    
    model.load_state_dict(torch.load(a.save_best, map_location=device))
    _, acc, preds, gts = validate(model, dl_te, crit, device)
    print(f"Best test accuracy {acc:.2f}%")

    pd.DataFrame(classification_report(gts, preds, output_dict=True)).T \
      .to_csv('metrics/report.csv')
    cm = confusion_matrix(gts, preds, normalize='true')
    plt.figure(figsize=(10,8))
    sns.heatmap(cm, cmap='YlGnBu', vmin=0, vmax=1, square=True)
    plt.xlabel('Pred'); plt.ylabel('GT'); plt.tight_layout()
    plt.savefig('metrics/confmat.png', dpi=250)
    print("📊 saved in ./metrics/")



if __name__ == '__main__':
    pa = argparse.ArgumentParser()
    pa.add_argument('--pkl', required=True,
                    help='Ruta al .pkl de keypoints (pyskl)')
    pa.add_argument('--train_split', default='xsub_train')
    pa.add_argument('--val_split',   default='xsub_val')
    pa.add_argument('--missing_txt', default='',
                    help='txt con frame_dir de clips corruptos')

    pa.add_argument('--pretrained', default='')
    pa.add_argument('--resume',     default='')

    pa.add_argument('--frames', type=int, default=16)
    pa.add_argument('--jitter', type=int, default=2)
    pa.add_argument('--drop_tokens', type=float, default=0.0)

    pa.add_argument('--batch', type=int, default=90)
    pa.add_argument('--epochs', type=int, default=120)
    pa.add_argument('--stop',   type=int, default=10)

    pa.add_argument('--lr',  type=float, default=5e-5)
    pa.add_argument('--wd',  type=float, default=1e-4)

    pa.add_argument('--d_model', type=int, default=192)
    pa.add_argument('--heads',   type=int, default=6)
    pa.add_argument('--layers',  type=int, default=8)
    pa.add_argument('--dropout', type=float, default=0.25)

    pa.add_argument('--scheduler',      choices=['cosine','onecycle'],
                    default='cosine')
    pa.add_argument('--warmup_epochs',  type=int, default=3)

    pa.add_argument('--freeze_n',       type=int, default=0)
    pa.add_argument('--unfreeze_epoch', type=int, default=15)

    pa.add_argument('--label_smooth', type=float, default=0.0)

    pa.add_argument('--device',     choices=['cpu','cuda'], default='cpu')
    pa.add_argument('--num_workers', type=int, default=2)

    pa.add_argument('--save_best', default='best_graphormer.pth')

    args = pa.parse_args()
    main(args)
